
题目

请根据步骤要求训练LDA主题模型。
In [1]:

import jieba
import re
from gensim.models import LdaModel
from gensim import corpora

1、对以下语料进行分词处理并去除停用词

raw_corpus = [
    '东京奥运会赛艇比赛女子四人双桨决赛，刷新世界最好成绩夺得冠军',
    '7月28日，王宗源/谢思埸夺得东京奥运会跳水男子双人三米板冠军。',
    '女子三人篮球杨舒予好绝！',
    '2021年是中国共产党成立100周年。为庆祝党的百年华诞，党中央决定举行一系列活动。',
    '中共中央宣传部3月24日公开发布中国共产党成立100周年庆祝活动标识。',
    '建党100年来,我们党始终坚持把加强党的建设摆在重要位置',
    '国内外各类休闲游戏、敏捷类休闲小游戏、益智休闲小游戏、单机休闲游戏',
    '一家专注网络游戏排行榜',
    '网络游戏社区,也是全球用户最多的数字娱乐平台。',
    '完善的游戏攻略专区,人气游戏论坛',
    '海量丰富的单机游戏补丁、单机游戏攻略秘籍、单机游戏评测专题等精彩内容'
]

In [2]:

#代码区
raw_corpus = [
    '东京奥运会赛艇比赛女子四人双桨决赛，刷新世界最好成绩夺得冠军',
    '7月28日，王宗源/谢思埸夺得东京奥运会跳水男子双人三米板冠军。',
    '女子三人篮球杨舒予好绝！',
    '2021年是中国共产党成立100周年。为庆祝党的百年华诞，党中央决定举行一系列活动。',
    '中共中央宣传部3月24日公开发布中国共产党成立100周年庆祝活动标识。',
    '建党100年来,我们党始终坚持把加强党的建设摆在重要位置',
    '国内外各类休闲游戏、敏捷类休闲小游戏、益智休闲小游戏、单机休闲游戏',
    '一家专注网络游戏排行榜',
    '网络游戏社区,也是全球用户最多的数字娱乐平台。',
    '完善的游戏攻略专区,人气游戏论坛',
    '海量丰富的单机游戏补丁、单机游戏攻略秘籍、单机游戏评测专题等精彩内容'
]
corpus = []
for sentence in raw_corpus:
    sentence = ''.join(re.findall(r'[\u4e00-\u9fa5]+', sentence))  # 仅保留中文
    stop_words = [
        '的', '了', '我', '你', '这', '也', '是', '谁', '呢', '后', '么',
        '啊', '哎', '该', '被', '着', '有', '就', '可', '还', '去', '却'
    ]  # 定义停止词
    corpus.append([item for item in jieba.cut(sentence) if item not in stop_words])  # 去掉停止词
corpus

Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.804 seconds.
Prefix dict has been built successfully.

Out [2]:

[['东京',
  '奥运会',
  '赛艇',
  '比赛',
  '女子',
  '四人',
  '双桨',
  '决赛',
  '刷新',
  '世界',
  '最好',
  '成绩',
  '夺得',
  '冠军'],
 ['月',
  '日',
  '王宗源',
  '谢思',
  '埸',
  '夺得',
  '东京',
  '奥运会',
  '跳水',
  '男子',
  '双人',
  '三米板',
  '冠军'],
 ['女子', '三人', '篮球', '杨舒予', '好', '绝'],
 ['年',
  '中国共产党',
  '成立',
  '周年',
  '为',
  '庆祝',
  '党',
  '百年',
  '华诞',
  '党中央',
  '决定',
  '举行',
  '一系列',
  '活动'],
 ['中共中央宣传部', '月', '日', '公开', '发布', '中国共产党', '成立', '周年', '庆祝', '活动', '标识'],
 ['建党', '年', '来', '我们', '党', '始终', '坚持', '把', '加强', '党的建设', '摆在', '重要', '位置'],
 ['国内外', '各类', '休闲游戏', '敏捷类', '休闲', '小游戏', '益智', '休闲', '小游戏', '单机', '休闲游戏'],
 ['一家', '专注', '网络游戏', '排行榜'],
 ['网络游戏', '社区', '全球', '用户', '最多', '数字', '娱乐', '平台'],
 ['完善', '游戏', '攻略', '专区', '人气', '游戏', '论坛'],
 ['海量',
  '丰富',
  '单机',
  '游戏补丁',
  '单机游戏',
  '攻略',
  '秘籍',
  '单机游戏',
  '评测',
  '专题',
  '等',
  '精彩内容']]

2、使用语料生成词典并保存到当前路径
In [3]:

#代码区
dictionary = corpora.Dictionary(corpus)
dictionary.save('corpus.dict')  # 把字典存储下来，可以在以后直接导入

3、将语料库中的句子向量化
In [4]:

#代码区
corpus = [dictionary.doc2bow(s) for s in corpus]
corpora.MmCorpus.serialize('corpus_bow.mm', corpus)  # 存储语料库

4、训练LDA主题模型并保存到当前路径

要求：主题数量：3; 模型命名：'corpus.model'
In [5]:

#代码区
num_topics = 3
chunksize = 2000
passes = 20
iterations = 400
eval_every = None

model = LdaModel(
    corpus=corpus,
    id2word=dictionary,
    chunksize=chunksize,
    alpha='auto',
    eta='auto',
    iterations=iterations,
    num_topics=num_topics,
    passes=passes,
    eval_every=eval_every
)

model.save('corpus.model')

5、将3个主题的主题词输出
In [6]:

#代码区
topic_list=model.print_topics(3)
print(topic_list)

[(0, '0.030*"日" + 0.030*"单机游戏" + 0.030*"休闲游戏" + 0.030*"单机" + 0.030*"小游戏" + 0.030*"月" + 0.030*"休闲" + 0.017*"周年" + 0.017*"活动" + 0.017*"中国共产党"'), (1, '0.028*"党" + 0.028*"建党" + 0.028*"年" + 0.028*"我们" + 0.028*"重要" + 0.028*"把" + 0.028*"来" + 0.028*"始终" + 0.028*"位置" + 0.028*"加强"'), (2, '0.029*"女子" + 0.029*"游戏" + 0.017*"网络游戏" + 0.017*"奥运会" + 0.017*"冠军" + 0.017*"夺得" + 0.017*"东京" + 0.017*"最好" + 0.017*"四人" + 0.017*"双桨"')]

6、输出原始语料中第5条句子对应的主题
In [8]:

#代码区
print(list(jieba.cut(raw_corpus[5])))
test_doc=list(jieba.cut(raw_corpus[5]))
doc_bow = dictionary.doc2bow(test_doc)      #文档转换成bow
doc_lda = model[doc_bow]
doc_lda

['建党', '100', '年来', ',', '我们', '党', '始终', '坚持', '把', '加强', '党的建设', '摆在', '重要', '位置']

Out [8]:

[(1, 0.98912936)]